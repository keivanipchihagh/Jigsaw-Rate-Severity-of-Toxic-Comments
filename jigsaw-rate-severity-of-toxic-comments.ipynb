{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Jigsaw Rate Severity of Toxic Comments\nSpecial thanks to:\n- [Jigsaw - Incredibly Simple Naive Bayes [0.768]](https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768)\n- [JRSoTC - RidgeRegression (ensemble of 3)](https://www.kaggle.com/steubk/jrsotc-ridgeregression-ensemble-of-3/notebook)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom copy import deepcopy\nimport scipy\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nstopwords = set(STOPWORDS)\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import Ridge","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:24.129315Z","iopub.execute_input":"2021-11-22T06:21:24.129947Z","iopub.status.idle":"2021-11-22T06:21:25.226027Z","shell.execute_reply.started":"2021-11-22T06:21:24.129854Z","shell.execute_reply":"2021-11-22T06:21:25.2253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 201","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:25.229827Z","iopub.execute_input":"2021-11-22T06:21:25.230133Z","iopub.status.idle":"2021-11-22T06:21:25.234421Z","shell.execute_reply.started":"2021-11-22T06:21:25.230091Z","shell.execute_reply":"2021-11-22T06:21:25.233621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Strategy ‚Åâ\nThere are three datasets introduced in the competition page. I will be using all three to build an Emsemble model. Datasets used in the notebook:\n- [jigsaw-toxic-comment-classification-challenge](https://www.kaggle.com/julian3833/jigsaw-toxic-comment-classification-challenge)\n- [jigsaw-unintended-bias-in-toxicity-classification](https://www.kaggle.com/julian3833/jigsaw-unintended-bias-in-toxicity-classification)","metadata":{}},{"cell_type":"code","source":"# Toxicity coefficients - These weights are used to combine all toxicity levels into one\ntoxicity_coefs = {\n    'toxic': 1,\n    'severe_toxic': 2,\n    'obscene': 1,\n    'threat': 1,\n    'insult': 1,\n    'identity_hate': 2,\n    'sexual_explicit': 1\n}\n\ntoxicity_types = list(toxicity_coefs.keys())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:25.235719Z","iopub.execute_input":"2021-11-22T06:21:25.236028Z","iopub.status.idle":"2021-11-22T06:21:25.245864Z","shell.execute_reply.started":"2021-11-22T06:21:25.235989Z","shell.execute_reply":"2021-11-22T06:21:25.245123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text Cleaning\nAs language models improve, text-cleaning is becoming less necessary, but that's not the case for all models. My strategy is to start simple and test some cleaning methods to see if they help the model or not.","metadata":{}},{"cell_type":"code","source":"HTML_TAG_PATTERN = r\"<.*?>\"\nEMAIL_PATTERN = r'(?:[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&\\'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\\\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])'\nURL_PATTERN = r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\nABBR_VERB_DICT = {\n    \"aren't\" : \"are not\",\n    \"arent\" : \"are not\",\n    \"can't\" : \"cannot\",\n    \"cant\" : \"cannot\",\n    \"couldn't\" : \"could not\",\n    \"couldnt\" : \"could not\",\n    \"didn't\" : \"did not\",\n    \"didnt\" : \"did not\",\n    \"doesn't\" : \"does not\",\n    \"doesnt\" : \"does not\",\n    \"don't\" : \"do not\",\n    \"dont\" : \"do not\",\n    \"hadn't\" : \"had not\",\n    \"hasn't\" : \"has not\",\n    \"haven't\" : \"have not\",\n    \"havent\" : \"have not\",\n    \"he'd\" : \"he would\",\n    \"he'll\" : \"he will\",\n    \"he's\" : \"he is\",\n    \"i'd\" : \"I would\",\n    \"i'd\" : \"I had\",\n    \"i'll\" : \"I will\",\n    \"i'm\" : \"I am\",\n    \"isn't\" : \"is not\",\n    \"it's\" : \"it is\",\n    \"it'll\":\"it will\",\n    \"i've\" : \"I have\",\n    \"let's\" : \"let us\",\n    \"mightn't\" : \"might not\",\n    \"mightnt\" : \"might not\",\n    \"mustn't\" : \"must not\",\n    \"shan't\" : \"shall not\",\n    \"she'd\" : \"she would\",\n    \"she'll\" : \"she will\",\n    \"she's\" : \"she is\",\n    \"shouldn't\" : \"should not\",\n    \"shouldnt\" : \"should not\",\n    \"shld\": \"should\",\n    \"that's\" : \"that is\",\n    \"thats\" : \"that is\",\n    \"there's\" : \"there is\",\n    \"theres\" : \"there is\",\n    \"they'd\" : \"they would\",\n    \"they'll\" : \"they will\",\n    \"they're\" : \"they are\",\n    \"theyre\":  \"they are\",\n    \"they've\" : \"they have\",\n    \"we'd\" : \"we would\",\n    \"we're\" : \"we are\",\n    \"weren't\" : \"were not\",\n    \"we've\" : \"we have\",\n    \"what'll\" : \"what will\",\n    \"what're\" : \"what are\",\n    \"what's\" : \"what is\",\n    \"what've\" : \"what have\",\n    \"where's\" : \"where is\",\n    \"who'd\" : \"who would\",\n    \"who'll\" : \"who will\",\n    \"who're\" : \"who are\",\n    \"who's\" : \"who is\",\n    \"who've\" : \"who have\",\n    \"won't\" : \"will not\",\n    \"wouldn't\" : \"would not\",\n    \"you'd\" : \"you would\",\n    \"you'll\" : \"you will\",\n    \"you're\" : \"you are\",\n    \"you've\" : \"you have\",\n    \"'re\": \" are\",\n    \"wasn't\": \"was not\",\n    \"we'll\":\" will\",    \n}\n\ndef remove_html_tags(string: str, replace_with: str = '') -> str:\n    return re.sub(pattern = HTML_TAG_PATTERN, repl = replace_with, string = string)\n\ndef fix_verb_abbr(string: str) -> str:\n    return ' '.join([ABBR_VERB_DICT[word.lower()] if (word.lower() in ABBR_VERB_DICT.keys()) else word for word in string.split()])\n\ndef remove_special_characters(string: str) -> str:\n    return ''.join(filter(lambda x: x in printable, string))\n\ndef remove_urls(string: str, replace_with: str = '') -> str:\n    return re.sub(pattern = URL_PATTERN, repl = replace_with, string = string)\n\ndef remove_emails(string: str, replace_with: str = '') -> str:\n    return re.sub(EMAIL_PATTERN, replace_with, string)\n\ndef remove_punctuation(string: str, punctuations: str) -> str:    \n    return string.translate(str.maketrans('', '', punctuations))\n\ndef remove_repeated_punctuations(string: str) -> str:\n    def replacement(match):\n        match = match.group()\n        return match[0] + (\" \" if \" \" in match else \"\")\n    return re.sub(r'[!\\\"#$%&\\'()*+,\\-.\\/:;<=>?@\\[\\\\\\]^_`{|}~ ]{2,}', replacement, string)\n\n\ndef clean_text(text):\n    \n    text = str(text)\n    \n     # Remove double quotations\n    text = text.replace('\"\"', '\"')\n    \n    # Replace new lines (\\n) with '.' and later remove consecutive repeated punctuations\n    text = text.replace('\\n', '. ')    \n    \n    text = remove_html_tags(text)                           # Remove HTML tags\n    text = remove_emails(text)                              # Remove email addresses\n    text = remove_urls(text)                                # Remove URLs\n#     text = fix_verb_abbr(text)                              # Fix verb abbreviations    \n    text = remove_special_characters(text)                  # Remove special characters\n    text = remove_repeated_punctuations(text)               # Remove consecutive repeated punctuations    \n    \n    # Strip leading and trailin puctuations and white spaces\n#     text = text.strip(punctuation).strip()\n    \n#     text = remove_punctuation(text, punctuations = '*~')    # Remove spesific puntuations\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:26:14.460226Z","iopub.status.idle":"2021-11-22T06:26:14.460997Z","shell.execute_reply.started":"2021-11-22T06:26:14.460696Z","shell.execute_reply":"2021-11-22T06:26:14.460729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Validation: Defining our Validation Method\nWe need to validate our model to tracks its performance. In the process, we use *validation_data.csv* as our validation set. I used *RMSE* and *Accuracy* as my metrics.\n\n**NOTE #1**: *Accuracy* is not a recommended metrics as our data is strongly unbalanced! ([See why](https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions/))","metadata":{}},{"cell_type":"code","source":"# Performs a Stratified K-Fold validation using the given pipeline\ndef kfold_validate(pipe, folds, X, y, less_toxic, more_toxic, verbose = False):\n    skf = StratifiedKFold(n_splits = folds, shuffle = True, random_state = RANDOM_STATE)\n    accuracies, rmse_scores = [], []    \n    \n    for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n        X_train, y_train = X[train_index], y[train_index]\n        X_val, y_val = X[val_index], y[val_index]\n        \n        # Fit the pipeline (Re-copy the pipeline to avoid fitting on the same one!)\n        _pipe = deepcopy(pipe)\n        _pipe.fit(X_train, y_train)\n        \n        # Calculate RMSE\n        rmse_score = mean_squared_error(_pipe.predict(X_val), y_val, squared = False) \n        rmse_scores.append(rmse_score)\n        \n        # Calculate accuracy\n        prob_1 = _pipe.predict(less_toxic)\n        prob_2 = _pipe.predict(more_toxic)\n        accuracy = (prob_1 < prob_2).mean()\n        accuracies.append(accuracy)\n        \n        if verbose:\n            print(f\"FOLD #{fold + 1}: Accuracy: {accuracy}, RMSE: {rmse_score}\")\n        \n    return np.array(accuracies).mean(), np.array(rmse_scores).mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:25.249738Z","iopub.execute_input":"2021-11-22T06:21:25.249973Z","iopub.status.idle":"2021-11-22T06:21:25.25968Z","shell.execute_reply.started":"2021-11-22T06:21:25.249945Z","shell.execute_reply":"2021-11-22T06:21:25.258827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization: Plotting the Data\nSince we pretty much do the same analysis all datasets, plots are converted into functions to avoid further duplication.","metadata":{}},{"cell_type":"code","source":"# Plots the didtribution of values in toxicity columns of the given dataframe\ndef plot_toxicity_dist(df):\n    toxicity_values = df['toxicity'].value_counts()\n    \n    plt.figure(figsize = (20, 5))\n    plt.title('Toxicity Level Distribution')\n    plt.bar(toxicity_values.keys(), toxicity_values.values, color = 'g')\n    plt.show()\n\n\n# Plots number of values for each toxicity level in the given dataframe\ndef plot_toxic_types_dist(df):    \n    fig = plt.figure(figsize = (20, 5))\n    plt.title('Toxicity Categories Count')\n    plt.bar([type for type in toxicity_types if type in jtc_df.columns], [df[type].value_counts()[1] for type in toxicity_types if type in df.columns], label = 'Number of occurrences')\n    plt.legend()\n    plt.show()\n\n\n# Plots the wordcloud for each toxicity level of the given data frame (Stopwords are removed)\ndef plot_wordcloud(df):\n    wordcloud = WordCloud(stopwords = stopwords)\n    fig, ax = plt.subplots(3, 2, figsize = (20, 10))\n\n    i = 0\n    for row in ax:\n        for col in row:        \n            wordcloud.generate(' '.join(df.loc[df[toxicity_types[i]] != 0, 'text'].tolist()))\n            col.set_title(toxicity_types[i])        \n            col.imshow(wordcloud)        \n            col.axis(\"off\")\n            i += 1\n    plt.tight_layout(pad = 0)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:25.261492Z","iopub.execute_input":"2021-11-22T06:21:25.262383Z","iopub.status.idle":"2021-11-22T06:21:25.275451Z","shell.execute_reply.started":"2021-11-22T06:21:25.262309Z","shell.execute_reply":"2021-11-22T06:21:25.27457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Jigsaw Rate Severity of Toxic Comments\nThis is our original dataset for the competition, let's take a look:\n- *comment_to_score.csv*: This is the final dataset that we have to make predictions on.\n- *validation_data.csv*: The dataset that will help validate our model.\n- *sample_submission.csv*: A sample submission file.","metadata":{}},{"cell_type":"code","source":"val_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\ntest_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n\nprint(f'test_df\\n- Shape: {test_df.shape}\\n- Columns: {list(test_df.columns)}\\n')\nprint(f'Duplicated texts: {test_df.duplicated(\"text\").sum()}')\n\nprint(f'val_df\\n- Shape: {val_df.shape}\\n- Columns: {list(val_df.columns)}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:25.27665Z","iopub.execute_input":"2021-11-22T06:21:25.277032Z","iopub.status.idle":"2021-11-22T06:21:26.02054Z","shell.execute_reply.started":"2021-11-22T06:21:25.276985Z","shell.execute_reply":"2021-11-22T06:21:26.019651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## jigsaw toxic comment classification challenge\nThis is the second dataset in the notebook. Let's take a look at what we have:\n- *train.csv*: The training data.\n- *test.csv*: The test data used for final prediction\n- *test_labels.csv*: The actual answers for the *test.csv*.\n- *sample_submission.csv*: A sample submission file.\n\n**NOTE #1**: Since the actual test labels are published, I will be using them to increase the number of training data.\n\n**NOTE #2**: I will be changing the columns names to match the original dataset columns' names. (This applies to all used datasets)","metadata":{}},{"cell_type":"markdown","source":"#### Loading the training data: *train.csv*","metadata":{}},{"cell_type":"code","source":"# Load both train.csv and test.csv with its corresponding test_labels.csv and Concatenate them into one\njtc_df = pd.concat([\n    pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv').rename(\n        columns = { 'id': 'comment_id', 'comment_text': 'text'}\n    ),\n    pd.merge(\n        pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv'),\n        pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv'),\n        on = 'id',\n        how = 'outer'\n    ).rename(columns = {'id': 'comment_id', 'comment_text': 'text'})\n])\n\nprint(f'- Shape: {jtc_df.shape}\\n- Columns: {list(jtc_df.columns)}\\n')\nprint(f'Duplicated texts: {jtc_df.duplicated(\"text\").sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:26.022084Z","iopub.execute_input":"2021-11-22T06:21:26.022926Z","iopub.status.idle":"2021-11-22T06:21:30.370649Z","shell.execute_reply.started":"2021-11-22T06:21:26.022887Z","shell.execute_reply":"2021-11-22T06:21:30.369873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Expanding the Data: Adding *test.csv* and *test_labels.csv*","metadata":{}},{"cell_type":"code","source":"# Combine all toxicity levels into one with the same weights set\njtc_df['toxicity'] = sum([jtc_df[type] * coef for type, coef in toxicity_coefs.items() if type in jtc_df])\n\n# Filter the ones with negative toxicity (They are invalid)\njtc_df = jtc_df.loc[jtc_df['toxicity'] >= 0]\n\nprint(f\"- New shape: {jtc_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:30.372118Z","iopub.execute_input":"2021-11-22T06:21:30.37253Z","iopub.status.idle":"2021-11-22T06:21:30.441841Z","shell.execute_reply.started":"2021-11-22T06:21:30.37249Z","shell.execute_reply":"2021-11-22T06:21:30.440982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Downsampling\nOur data is heavily unblanaced ([See why that's bad](https://machinelearningmastery.com/what-is-imbalanced-classification/)) and we must fix it. There are a few tricks we can pull off but down-sampling is the best way to go.","metadata":{}},{"cell_type":"code","source":"# Cutoff & threshold\ncutoff = (jtc_df['toxicity'] > 0).sum()\ncutoff_coef = 1.5\n\n# Downsample non-toxic comments\njtc_non_toxic_df = jtc_df.loc[jtc_df['toxicity'] <= 0].sample(int(cutoff * cutoff_coef), random_state = RANDOM_STATE)\n\n# Concatenate the two dataframes\njtc_df = pd.concat([jtc_non_toxic_df, jtc_df[jtc_df['toxicity'] > 0]])\n\nprint(f\"- New shape: {jtc_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:30.443843Z","iopub.execute_input":"2021-11-22T06:21:30.444332Z","iopub.status.idle":"2021-11-22T06:21:30.524892Z","shell.execute_reply.started":"2021-11-22T06:21:30.444282Z","shell.execute_reply":"2021-11-22T06:21:30.52404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA: Exploratory Data Analysis\nOur data from **jigsaw-toxic-comment-classification-challenge** is ready to be fed into a model and then prediction, which results in a clean 77% score on the submission. I did further explorations on the data but to keep things short, they are commented out below. (Run in seperate cells)","metadata":{}},{"cell_type":"code","source":"# plot_toxic_types_dist(jtc_df)\n# plot_toxicity_dist(jtc_df)\n# plot_wordcloud(jtc_df)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:30.529062Z","iopub.execute_input":"2021-11-22T06:21:30.529392Z","iopub.status.idle":"2021-11-22T06:21:30.535904Z","shell.execute_reply.started":"2021-11-22T06:21:30.529356Z","shell.execute_reply":"2021-11-22T06:21:30.535021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## jigsaw unintended bias in toxicity classification\nOur third dataset has many dataframes but luckily *all_data.csv* contains them all.\n\n**NOTE #1**: The *toxicity_annotator_count* feature can be used to remove the comments with very few annotators. I'll remove the ones with less than 10 annotators.\n\n**NOTE #2**: The *sexual_explicit* feature is new, but keeping it might be a good idea, why?","metadata":{}},{"cell_type":"code","source":"jutc_features_to_select = ['comment_id', 'text', 'toxic', 'severe_toxic', 'obscene', 'insult', 'identity_hate', 'sexual_explicit', 'toxicity_annotator_count']\n\n# Load and rename columns\njutc_df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv').rename(\n    columns = {\n        'id': 'comment_id',\n        'comment_text': 'text',\n        'identity_attack': 'identity_hate',\n        'toxicity': 'toxic',\n        'severe_toxicity': 'severe_toxic'\n    }\n)\n\n# Filter annonators and select only the features we need\njutc_df = jutc_df.loc[jutc_df['toxicity_annotator_count'] > 5, jutc_features_to_select]\n\nprint(f'- Shape: {jutc_df.shape}\\n- Columns: {list(jutc_df.columns)}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:30.537063Z","iopub.execute_input":"2021-11-22T06:21:30.537394Z","iopub.status.idle":"2021-11-22T06:21:59.486445Z","shell.execute_reply.started":"2021-11-22T06:21:30.53736Z","shell.execute_reply":"2021-11-22T06:21:59.485744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate toxicity\njutc_df['toxicity'] = jutc_df[['severe_toxic', 'obscene', 'insult', 'identity_hate', 'sexual_explicit']].sum(axis = 1)\n\njutc_df['toxicity'] = jutc_df.apply(lambda x: x[\"toxic\"] if x[\"toxic\"] <= 0.5 else x[\"toxicity\"], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:21:59.493288Z","iopub.execute_input":"2021-11-22T06:21:59.493792Z","iopub.status.idle":"2021-11-22T06:22:11.470253Z","shell.execute_reply.started":"2021-11-22T06:21:59.493758Z","shell.execute_reply":"2021-11-22T06:22:11.468938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Downsampling\nThis dataset is more balanced that the previous one, but still requires dow-sampling.","metadata":{}},{"cell_type":"code","source":"# Cutoff and threshold\ncutoff = (jutc_df['toxicity'] > 0.5).sum()\ncutoff_coef = 1.5\n\n# Downsample non-toxic comments\njutc_non_toxic_df = jutc_df[jutc_df['toxicity'] <= 0.5].sample(int(cutoff * cutoff_coef), random_state = RANDOM_STATE)\n\n# Concatenate the two dataframes\njutc_df = pd.concat([jutc_non_toxic_df, jutc_df[jutc_df['toxicity'] > 0.5]])\n\nprint(f'- Shape: {jutc_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:22:11.472143Z","iopub.execute_input":"2021-11-22T06:22:11.472617Z","iopub.status.idle":"2021-11-22T06:22:11.683306Z","shell.execute_reply.started":"2021-11-22T06:22:11.47258Z","shell.execute_reply":"2021-11-22T06:22:11.682554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to discrete valeus (instead of continuous)\njutc_df['toxicity'] = (np.round(jutc_df['toxicity'], decimals = 1) * 10).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:22:11.688925Z","iopub.execute_input":"2021-11-22T06:22:11.68934Z","iopub.status.idle":"2021-11-22T06:22:11.705893Z","shell.execute_reply.started":"2021-11-22T06:22:11.68931Z","shell.execute_reply":"2021-11-22T06:22:11.705086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA: Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# plot_toxicity_dist(jutc_df)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:22:11.70719Z","iopub.execute_input":"2021-11-22T06:22:11.707449Z","iopub.status.idle":"2021-11-22T06:22:11.713656Z","shell.execute_reply.started":"2021-11-22T06:22:11.707421Z","shell.execute_reply":"2021-11-22T06:22:11.713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling: Creating the Pipeline","metadata":{}},{"cell_type":"code","source":"train_X = jtc_df['text']\ntrain_y = jtc_df['toxicity']\ntest_X = test_df['text']\n\n# train_X = jutc_df['text']\n# train_y = jutc_df['toxicity']\n# test_X = test_df['text']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:22:11.714995Z","iopub.execute_input":"2021-11-22T06:22:11.715346Z","iopub.status.idle":"2021-11-22T06:22:11.724741Z","shell.execute_reply.started":"2021-11-22T06:22:11.715298Z","shell.execute_reply":"2021-11-22T06:22:11.724085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define pipeline\npipe = Pipeline([\n    ('vectorizer', TfidfVectorizer(analyzer = 'char_wb', max_df = 0.5, min_df = 3, ngram_range = (3, 5))),\n    ('model', Ridge())\n])\n\n# Validate (Pipeline must not be fitted!)\nacc_mean, rmse_mean = kfold_validate(\n    pipe = pipe,\n    folds = 5,\n    X = np.array(train_X),\n    y = np.array(train_y),\n    less_toxic = val_df['less_toxic'],\n    more_toxic = val_df['more_toxic'],\n    verbose = True\n)\nprint(f\"Mean Accuracy: {acc_mean}\\nMean RMSE: {rmse_mean}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:22:11.725951Z","iopub.execute_input":"2021-11-22T06:22:11.726353Z","iopub.status.idle":"2021-11-22T06:26:14.455731Z","shell.execute_reply.started":"2021-11-22T06:22:11.726311Z","shell.execute_reply":"2021-11-22T06:26:14.454059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating the Submission","metadata":{}},{"cell_type":"code","source":"# Train the pipeline\npipe.fit(train_X, train_y)\n\n# Make predictions\ny_pred = pipe.predict(test_X)\n\n# Rank the predictions to avoid ties\ny_pred = scipy.stats.rankdata(y_pred, method = 'ordinal')\n\n# Create submission file\nsubmission_df = pd.DataFrame(data = {\n    'comment_id': test_df['comment_id'],\n    'score': y_pred\n}).to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:26:14.457052Z","iopub.status.idle":"2021-11-22T06:26:14.458002Z","shell.execute_reply.started":"2021-11-22T06:26:14.457689Z","shell.execute_reply":"2021-11-22T06:26:14.457721Z"},"trusted":true},"execution_count":null,"outputs":[]}]}